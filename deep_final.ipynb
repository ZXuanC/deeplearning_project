{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Final Project   ID:3034093"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this project, I would use tensorflow as a tool to compare with how convolutional neural networks(CNNs) could help us got better result. However I found a really stunning thing that tensorflow was not totally support for python 3.6.3, so I should write my code in python 3.5.4. Most of coding skills and API referred from tensorflow official websites."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Mixed National Institute of Standards and Technology database(MNIST) is the database which saved many different areas' handwritten numbers and all results were standard. This sounds like an ideal database for beginners at tensorflow and CNNs. So we input mnist from tensorflow."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/Cellar/python3/3.6.3/Frameworks/Python.framework/Versions/3.6/lib/python3.6/importlib/_bootstrap.py:219: RuntimeWarning: compiletime version 3.5 of module 'tensorflow.python.framework.fast_tensor_util' does not match runtime version 3.6\n",
      "  return f(*args, **kwds)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting MNIST_data/train-images-idx3-ubyte.gz\n",
      "Extracting MNIST_data/train-labels-idx1-ubyte.gz\n",
      "Extracting MNIST_data/t10k-images-idx3-ubyte.gz\n",
      "Extracting MNIST_data/t10k-labels-idx1-ubyte.gz\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.examples.tutorials.mnist import input_data\n",
    "import matplotlib.pyplot as plt\n",
    "mnist = input_data.read_data_sets('MNIST_data', one_hot=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here is a very simple training MNIST via tensorflow, and we can find that the accuracy only around 90%. It seems not really a good trainer in the result. That is the reason why we need to use CNNs model to help us get higher accuracy. (Considered the training speed and CPU, I only use 2000 steps and catch 200 data points once.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /usr/local/lib/python3.6/site-packages/tensorflow/python/util/tf_should_use.py:107: initialize_all_variables (from tensorflow.python.ops.variables) is deprecated and will be removed after 2017-03-02.\n",
      "Instructions for updating:\n",
      "Use `tf.global_variables_initializer` instead.\n",
      "0.4888\n",
      "0.8576\n",
      "0.9146\n",
      "0.8981\n",
      "0.9006\n",
      "0.9199\n",
      "0.9091\n",
      "0.9077\n",
      "0.8454\n",
      "0.8883\n"
     ]
    }
   ],
   "source": [
    "x_simple = tf.placeholder(tf.float32, [None, 784]) #784 = 28 * 28\n",
    "Weight_simple = tf.Variable(tf.zeros([784,10])) # 10 = 0~9\n",
    "bias_simple = tf.Variable(tf.zeros([10]))\n",
    "\n",
    "Prediction = tf.nn.softmax(tf.matmul(x_simple,Weight_simple) + bias_simple)\n",
    "y_simple = tf.placeholder(\"float\", [None,10])\n",
    "loss_simple = -tf.reduce_sum(y_simple*tf.log(Prediction))\n",
    "\n",
    "train_step = tf.train.GradientDescentOptimizer(0.01).minimize(loss_simple)\n",
    "init = tf.initialize_all_variables()\n",
    "\n",
    "sess = tf.Session()\n",
    "sess.run(init)\n",
    "\n",
    "for i in range(2000):\n",
    "    batch_x, batch_y = mnist.train.next_batch(200)\n",
    "    sess.run(train_step, feed_dict={x_simple: batch_x, y_simple: batch_y})\n",
    "    correct_prediction = tf.equal(tf.argmax(Prediction,1), tf.argmax(y_simple,1))\n",
    "    accuracy = tf.reduce_mean(tf.cast(correct_prediction, \"float\"))\n",
    "    if i % 200 == 0: \n",
    "        print(sess.run(accuracy, feed_dict={x_simple: mnist.test.images, y_simple: mnist.test.labels}))  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now I try to apply CNNs model to the code and define somethings as much as I can. Most of parameters also refer from tensorflow official website."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def compute_accuracy(v_xs, v_ys):\n",
    "    global prediction\n",
    "    y_pre = sess.run(prediction, feed_dict={x: v_xs, keep_drop: 1})\n",
    "    correct_prediction = tf.equal(tf.argmax(y_pre,1), tf.argmax(v_ys,1))\n",
    "    accuracy = tf.reduce_mean(tf.cast(correct_prediction, tf.float32))\n",
    "    result = sess.run(accuracy, feed_dict={x: v_xs, y: v_ys, keep_drop: 1})\n",
    "    return result\n",
    "\n",
    "def weight(shape):\n",
    "    initial = tf.truncated_normal(shape, stddev=0.1)\n",
    "    return tf.Variable(initial)\n",
    "\n",
    "def bias(shape):\n",
    "    initial = tf.constant(0.1, shape=shape)\n",
    "    return tf.Variable(initial)\n",
    "\n",
    "def conv2d(x, W):\n",
    "    return tf.nn.conv2d(x, W, strides=[1, 1, 1, 1], padding='SAME')\n",
    "\n",
    "def max_pool_2x2(x):\n",
    "    return tf.nn.max_pool(x, ksize=[1,2,2,1], strides=[1,2,2,1], padding='SAME')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.1885\n",
      "0.9215\n",
      "0.945\n",
      "0.955\n",
      "0.9645\n",
      "0.969\n",
      "0.973\n",
      "0.9725\n",
      "0.9745\n",
      "0.977\n"
     ]
    }
   ],
   "source": [
    "x = tf.placeholder(tf.float32, [None, 784]) \n",
    "y = tf.placeholder(tf.float32, [None, 10])\n",
    "keep_drop = tf.placeholder(tf.float32)\n",
    "\n",
    "x_image = tf.reshape(x,[-1,28,28,1])\n",
    "\n",
    "##conv1 layer ##\n",
    "W_conv1 = weight([5,5,1,32])\n",
    "b_conv1 = bias([32])\n",
    "h_conv1 = tf.nn.relu(conv2d(x_image,W_conv1)+b_conv1)\n",
    "h_pool1 = max_pool_2x2(h_conv1)\n",
    "\n",
    "## conv2 layer ##\n",
    "W_conv2 = weight([5,5,32,64])\n",
    "b_conv2 = bias([64])\n",
    "h_conv2 = tf.nn.relu(conv2d(h_pool1,W_conv2)+b_conv2)\n",
    "h_pool2 = max_pool_2x2(h_conv2)\n",
    "## func1 layer ##\n",
    "W_fc1 = weight([7*7*64,1024])\n",
    "b_fc1 = bias([1024])\n",
    "\n",
    "h_pool2_flat = tf.reshape(h_pool2,[-1,7*7*64])\n",
    "h_fc1 = tf.nn.relu(tf.matmul(h_pool2_flat,W_fc1)+b_fc1)\n",
    "h_fcl_drop = tf.nn.dropout(h_fc1,keep_drop)\n",
    "\n",
    "## func2 layer ##\n",
    "W_fc2 = weight([1024,10])\n",
    "b_fc2 = bias([10])\n",
    "\n",
    "prediction =tf.nn.softmax(tf.matmul(h_fcl_drop,W_fc2)+b_fc2)\n",
    "\n",
    "loss = tf.reduce_mean(-tf.reduce_sum(y * tf.log(prediction),reduction_indices=[1]))\n",
    "train_step = tf.train.AdamOptimizer(0.0001).minimize(loss)\n",
    "\n",
    "sess = tf.Session()\n",
    "sess.run(tf.initialize_all_variables())\n",
    "\n",
    "for i in range(2000):\n",
    "    batch_x, batch_y = mnist.train.next_batch(200)\n",
    "    sess.run(train_step, feed_dict={x: batch_x, y: batch_y, keep_drop: 0.5})\n",
    "    if i % 200 == 0:\n",
    "        print(compute_accuracy(mnist.test.images[:2000], mnist.test.labels[:2000]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Conclusion "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "According to the results, we can find an obvious increasing when we apply CNNs to help us training data. Furthermore, we could keep getting better and better result if we apply more layers. Since CNNs is a training model which can give highly training consequence, there are so many newest technologies need to rely on CNNs. My future research also will use CNNs to do some image processing related, and I can't wait for next quarter!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Reference "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://jermwatt.github.io/mlrefined/presentations/Convolutional_Networks/conv_presentation.slides.html\n",
    " \n",
    "https://www.tensorflow.org\n",
    " \n",
    "https://github.com/MorvanZhou"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
